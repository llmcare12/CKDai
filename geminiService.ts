import { GoogleGenAI, Modality } from "@google/genai";
import { 
  GEMINI_MODEL_FLASH, 
  GEMINI_MODEL_TTS, 
  RAG_KNOWLEDGE_DB, // è¨˜å¾—ç¢ºèª constants.ts æœ‰ export é€™ä¸‰å€‹
  FIXED_QNA_LIST,
  KnowledgeItem 
} from "./constants";
import { MindMapNode } from "../types";

const getClient = () => {
  const apiKey = process.env.API_KEY;
  if (!apiKey) {
    throw new Error("API_KEY environment variable is not set");
  }
  return new GoogleGenAI({ apiKey });
};

// Helper to clean JSON string from Markdown code blocks
const cleanJson = (text: string): string => {
  let clean = text.trim();
  if (clean.startsWith('```')) {
    clean = clean.replace(/^```(json)?/, '').replace(/```$/, '');
  }
  return clean.trim();
};

// ==========================================
// RAG æ ¸å¿ƒå·¥å…·å‡½å¼ (æ”¾åœ¨åŒä¸€æª”æ¡ˆæ–¹ä¾¿å‘¼å«)
// ==========================================

// 1. å›ºå®šå•ç­”ç²¾æº–åŒ¹é… (å„ªå…ˆç´šæœ€é«˜ï¼Œçœ Token)
function findFixedAnswer(query: string): string | null {
  const target = FIXED_QNA_LIST.find(item => 
    item.question.includes(query) || query.includes(item.question)
  );
  return target ? target.answer : null;
}

// 2. æ¨¡ç³Šæª¢ç´¢ (æ‰¾å‡ºæœ€ç›¸é—œçš„çŸ¥è­˜ç‰‡æ®µ)
function retrieveContext(query: string, topK: number = 3): KnowledgeItem[] {
  const lowerQuery = query.toLowerCase();
  
  // ç°¡æ˜“è¨ˆåˆ†æ©Ÿåˆ¶
  const scoredData = RAG_KNOWLEDGE_DB.map(item => {
    let score = 0;
    if (item.topic.includes(query)) score += 10;          // æ¨™é¡Œå‘½ä¸­æ¬Šé‡æœ€é«˜
    if (item.content.includes(query)) score += 5;         // å…§å®¹å‘½ä¸­
    if (item.summary.includes(query)) score += 3;         // æ‘˜è¦å‘½ä¸­
    const keywordMatch = item.keywords.some(k => lowerQuery.includes(k.toLowerCase()));
    if (keywordMatch) score += 8;                         // é—œéµå­—å‘½ä¸­

    return { item, score };
  });

  // éæ¿¾æ‰æ²’åˆ†æ•¸çš„ï¼Œç”±é«˜åˆ†æ’åˆ°ä½åˆ†ï¼Œå–å‰ K ç­†
  return scoredData
    .filter(d => d.score > 0)
    .sort((a, b) => b.score - a.score)
    .slice(0, topK)
    .map(d => d.item);
}

// 3. å°‡æª¢ç´¢åˆ°çš„è³‡æ–™è½‰ç‚ºæ–‡å­— Prompt
function formatContextToPrompt(items: KnowledgeItem[]): string {
  if (items.length === 0) return "ç›®å‰è³‡æ–™åº«ä¸­ç„¡ç›´æ¥ç›¸é—œè³‡è¨Šï¼Œä¸¦æé†’ä½¿ç”¨è€…è«®è©¢é†«å¸«ã€‚";
  return items.map((item, idx) => `
  [è³‡æ–™ ${idx + 1}]
  ä¸»é¡Œï¼š${item.topic}
  æ‘˜è¦ï¼š${item.summary}
  å…§å®¹ï¼š${item.content}
  `).join('\n---\n');
}


// ==========================================
// ä¸»è¦ Service åŠŸèƒ½
// ==========================================
// ==========================================
// 1. AI æ‘˜è¦ï¼ŒèŠå¤©æ©Ÿå™¨äºº (RAG å¢å¼·ç‰ˆ + é£²é£Ÿæ™ºæ…§åå•)
// ==========================================
export const generateChatResponse = async (
  userMessage: string, 
  history: { role: string; content: string }[]
): Promise<string> => {
  
  // Step A: å…ˆæª¢æŸ¥å›ºå®šå•ç­” (ç§’å›ï¼Œä¸æ¶ˆè€— API)
  const fixedAns = findFixedAnswer(userMessage);
  if (fixedAns) {
    return fixedAns; 
  }

  // Step B: åŸ·è¡Œ RAG æª¢ç´¢
  // æŠ€å·§ï¼šå¦‚æœä½¿ç”¨è€…å•çš„æ˜¯å…·é«”é£Ÿç‰©(å¦‚æ»·è‚‰é£¯)ï¼ŒRAG å¯èƒ½æ‰¾ä¸åˆ°æ»·è‚‰é£¯çš„æ¢ç›®ï¼Œ
  // ä½†æœƒæ‰¾åˆ°ã€Œä½è›‹ç™½é£²é£Ÿã€ã€ã€Œéˆ‰é™åˆ¶ã€ç­‰é€šå‰‡ï¼Œé€™äº›é€šå‰‡å° AI åˆ¤æ–·å¾ˆé‡è¦ã€‚
  const retrievedItems = retrieveContext(userMessage, 5); 
  const contextPrompt = formatContextToPrompt(retrievedItems);

  const ai = getClient();
  
  // Step C: å‘¼å« Gemini (æ ¸å¿ƒä¿®æ”¹è™•ï¼šSystem Instruction)
  const response = await ai.models.generateContent({
    model: GEMINI_MODEL_FLASH,
    contents: [
      ...history.map(msg => ({
        role: msg.role,
        parts: [{ text: msg.content }]
      })),
      { role: 'user', parts: [{ text: userMessage }] }
    ],
    config: {
      // âœ¨ é€™è£¡åŠ å…¥äº†ã€Œé£²é£Ÿåˆ†æåˆ¤æ–·é‚è¼¯ã€
      systemInstruction: `ä½ æ˜¯ä¸€ä½å°ˆæ¥­ã€è¦ªåˆ‡çš„è…è‡Ÿç—…è¡›æ•™ AI åŠ©ç†ã€ŒKidneyCare AIã€ã€‚
      
      ã€ä»»å‹™ç›®æ¨™ã€‘
      æ ¹æ“šã€æª¢ç´¢åˆ°çš„è¡›æ•™è³‡æ–™ã€‘å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚

      ã€æª¢ç´¢åˆ°çš„è¡›æ•™è³‡æ–™ã€‘ï¼š
      ${contextPrompt}
      
      ã€å›ç­”æ ¸å¿ƒè¦å‰‡ (é‡è¦)ã€‘
      1. **ä¸€èˆ¬å•é¡Œ**ï¼šè‹¥ä½¿ç”¨è€…å•çš„æ˜¯å®šç¾©ã€ç—‡ç‹€ã€åŸå‰‡ (ä¾‹å¦‚ï¼šä»€éº¼æ˜¯é«˜è¡€ç£·ï¼Ÿ)ï¼Œè«‹ç›´æ¥ä¾æ“šè³‡æ–™å›ç­”ã€‚
      2. **é£²é£Ÿ/é£Ÿç‰©åˆ†æå•é¡Œ (Smart Check)**ï¼š
         ç•¶ä½¿ç”¨è€…è©¢å•ã€ŒæŸç¨®é£Ÿç‰©èƒ½ä¸èƒ½åƒï¼Ÿã€æˆ–ã€Œé£²é£Ÿå»ºè­°ã€æ™‚ï¼Œä½ å¿…é ˆåŸ·è¡Œä»¥ä¸‹åˆ¤æ–·ï¼š
         - **æª¢æŸ¥è³‡è¨Š**ï¼šåˆ¤æ–·ä½¿ç”¨è€…çš„å°è©±ä¸­(åŒ…å«æ­·å²è¨Šæ¯)æ˜¯å¦å·²æä¾›**ã€Œè…è‡Ÿç—…éšæ®µã€**(å¦‚ï¼šç¬¬å¹¾æœŸã€G3ã€æ´—è…ä¸­ã€é€æä¸­) æˆ– **ã€Œå…±ç—…ç—‡ã€**(å¦‚ï¼šç³–å°¿ç—…)ã€‚
         - **ğŸ”´ è³‡è¨Šä¸è¶³æ™‚**ï¼šè«‹**ä¸è¦**ç›´æ¥çµ¦å‡ºå»ºè­°ã€‚è«‹ç¦®è²Œåœ°åå•ï¼šã€Œç‚ºäº†çµ¦æ‚¨æ­£ç¢ºçš„å»ºè­°ï¼Œè«‹å•æ‚¨ç›®å‰çš„è…è‡ŸåŠŸèƒ½å¤§ç´„åœ¨ç¬¬å¹¾æœŸï¼Ÿæˆ–æ˜¯å·²ç¶“é–‹å§‹æ´—è…äº†å—ï¼Ÿ(å› ç‚ºæ´—è…å‰å¾Œçš„é£²é£ŸåŸå‰‡æ˜¯ç›¸åçš„å–”ï¼)ã€
         - **ğŸŸ¢ è³‡è¨Šå……è¶³æ™‚**ï¼šè«‹æ ¹æ“šä½¿ç”¨è€…çš„éšæ®µ (æœªæ´—è…éœ€ä½è›‹ç™½/æ´—è…éœ€é«˜è›‹ç™½)ï¼Œçµåˆæª¢ç´¢è³‡æ–™ä¸­çš„éˆ‰ã€ç£·ã€é‰€é™åˆ¶è¦å‰‡ï¼Œçµ¦å‡ºè©²é£Ÿç‰©çš„ã€Œé©åˆåº¦ç‡ˆè™Ÿ (ğŸŸ¢/ğŸŸ¡/ğŸ”´)ã€èˆ‡ã€Œæ”¹è‰¯å»ºè­°ã€ã€‚

      ã€èªæ°£èˆ‡æ’ç‰ˆã€‘
      1. æº«æš–ã€å…·å‚™åŒç†å¿ƒã€‚
      2. **çµ•å°ä¸è¦ä½¿ç”¨ Markdown çš„ç²—é«”èªæ³• (å¦‚ **æ–‡å­—**)ï¼Œè«‹ä½¿ç”¨ç´”æ–‡å­—æ’ç‰ˆã€‚**
      3. è‹¥è³‡æ–™åº«ç„¡ç›¸é—œè³‡è¨Šä¸”ç„¡æ³•åˆ¤æ–·ï¼Œè«‹å»ºè­°è«®è©¢é†«å¸«ã€‚`,
    }
  });

  return response.text || "æŠ±æ­‰ï¼Œæˆ‘ç¾åœ¨ç„¡æ³•å›ç­”ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚";
};

// 2. èªéŸ³ç”Ÿæˆ (RAG å¢å¼·ç‰ˆ)
export const generatePodcastAudio = async (topic: string): Promise<{ audioUrl: string, script: string }> => {
  const ai = getClient();

  // é‡å°ä¸»é¡Œæª¢ç´¢è³‡æ–™ (Podcast éœ€è¦è¼ƒå¤šç´ æï¼Œæˆ‘å€‘æŠ“å–å‰ 6 ç­†)
  const retrievedItems = retrieveContext(topic, 6);
  const contextPrompt = formatContextToPrompt(retrievedItems);

  // Step 1: ç”Ÿæˆé€å­—ç¨¿
  const scriptResponse = await ai.models.generateContent({
    model: GEMINI_MODEL_FLASH,
    contents: `è«‹æ ¹æ“šä»¥ä¸‹æª¢ç´¢åˆ°çš„è¡›æ•™è³‡æ–™ï¼Œç‚ºä¸»é¡Œã€Œ${topic}ã€æ’°å¯«ä¸€ä»½ Podcast å»£æ’­è…³æœ¬ã€‚
    
    åƒè€ƒè³‡æ–™ï¼š
    ${contextPrompt}
    
    è¦æ±‚ï¼š
    1. é•·åº¦ç´„ 500 å­— (å£èªæœ—è®€ç´„ 2-3 åˆ†é˜)ã€‚
    2. è§’è‰²ï¼šä¸€ä½è¦ªåˆ‡ã€æ´»æ½‘çš„ç”·æ€§ä¾†è‡ªã€Œå°åŒ—æ¦®ç¸½ã€çš„è³‡æ·±è…è‡Ÿç—…è¡›æ•™å€‹ç®¡å¸«ï¼Œåå­—å«å°æ¦®ã€‚
    3. èªæ°£ï¼šéå¸¸å£èªåŒ–ã€è¼•é¬†ã€æº«æš–ã€‚å¤šç”¨ã€Œå¤§å®¶çŸ¥é“å—ï¼Ÿã€ã€ã€Œå…¶å¯¦å‘€...ã€é€™é¡èªåŠ©è©ã€‚
    4. å…§å®¹å¿…é ˆåŸºæ–¼åƒè€ƒè³‡æ–™ï¼Œä¸è¦æ†‘ç©ºæé€ æ•¸æ“šã€‚
    5. è¼¸å‡ºæ ¼å¼ï¼šç´”æ–‡å­—è…³æœ¬ï¼Œä¸è¦åŒ…å« [éŸ³æ¨‚]ã€(ç¬‘è²) ç­‰æ¨™è¨˜ã€‚
    6. ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚`,
  });

  const scriptText = scriptResponse.text || "ç„¡æ³•ç”Ÿæˆè…³æœ¬ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚";

  // Step 2: ç”¨TTSè½‰èªéŸ³
  const audioResponse = await ai.models.generateContent({
    model: GEMINI_MODEL_TTS,
    contents: [{ parts: [{ text: scriptText }] }],
    config: {
      responseModalities: [Modality.AUDIO],
      speechConfig: {
        voiceConfig: {
          prebuiltVoiceConfig: { voiceName: 'Charon' }, 
        },
      },
    },
  });

  const base64Audio = audioResponse.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
  
  if (!base64Audio) {
    throw new Error("Failed to generate audio");
  }

  const audioBuffer = decode(base64Audio);
  const wavBytes = createWavFile(audioBuffer, 24000, 1); 
  const blob = new Blob([wavBytes], { type: 'audio/wav' });
  const audioUrl = URL.createObjectURL(blob);

  return { audioUrl, script: scriptText };
};

// 3. å¿ƒæ™ºåœ–è³‡æ–™ç”Ÿæˆ (RAG å¢å¼·ç‰ˆ)
export const generateMindMapData = async (topic: string): Promise<MindMapNode> => {
  const ai = getClient();

  // é‡å°ä¸»é¡Œæª¢ç´¢è³‡æ–™
  const retrievedItems = retrieveContext(topic, 5);
  const contextPrompt = formatContextToPrompt(retrievedItems);

  const response = await ai.models.generateContent({
    model: GEMINI_MODEL_FLASH,
    contents: `è«‹æ ¹æ“šä»¥ä¸‹è¡›æ•™è³‡æ–™ï¼Œé‡å°ä¸»é¡Œã€Œ${topic}ã€è£½ä½œä¸€å€‹å¿ƒæ™ºåœ–çµæ§‹ã€‚
    
    åƒè€ƒè³‡æ–™ï¼š
    ${contextPrompt}
    
    è¦æ±‚ï¼š
    1. åƒ…ä½¿ç”¨ä¸Šè¿°è³‡æ–™åº«å…§çš„è³‡è¨Šã€‚
    2. è«‹å›å‚³ä¸€å€‹æ¨™æº–çš„ JSON ç‰©ä»¶ã€‚
    3. æ ¹ç¯€é» (Root) æ˜¯ä¸»é¡Œåç¨±ï¼š${topic}ã€‚
    4. æ¯å€‹ç¯€é»çµæ§‹å¿…é ˆåŒ…å« 'name' (å­—ä¸²) å’Œ 'children' (é™£åˆ—)ã€‚
    5. å±¤æ¬¡åˆ†æ˜ï¼Œè‡³å°‘ 3 å±¤çµæ§‹ã€‚
    6. ä¸è¦åŒ…å«ä»»ä½• Markdown æ¨™è¨˜ï¼Œåªå›å‚³ç´” JSON å­—ä¸²ã€‚`,
    config: {
      responseMimeType: "application/json"
    }
  });

  const jsonStr = response.text;
  if (!jsonStr) throw new Error("No data returned");
  
  try {
    const cleanStr = cleanJson(jsonStr);
    return JSON.parse(cleanStr) as MindMapNode;
  } catch (e) {
    console.error("JSON Parse Error:", e, jsonStr);
    throw new Error("ç„¡æ³•è§£æå¿ƒæ™ºåœ–è³‡æ–™ï¼Œè«‹é‡è©¦ã€‚");
  }
};

// --- Audio Helper Functions (Raw PCM to WAV) ---
function decode(base64: string): Uint8Array {
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

function createWavFile(samples: Uint8Array, sampleRate: number, numChannels: number): Uint8Array {
    const buffer = new ArrayBuffer(44 + samples.length);
    const view = new DataView(buffer);
    const dataSize = samples.length;
    
    writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + dataSize, true);
    writeString(view, 8, 'WAVE');
    writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true); // PCM
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * numChannels * 2, true);
    view.setUint16(32, numChannels * 2, true);
    view.setUint16(34, 16, true);
    writeString(view, 36, 'data');
    view.setUint32(40, dataSize, true);
    
    const wavBytes = new Uint8Array(buffer);
    wavBytes.set(samples, 44);
    return wavBytes;
}

function writeString(view: DataView, offset: number, string: string) {
  for (let i = 0; i < string.length; i++) {
    view.setUint8(offset + i, string.charCodeAt(i));
  }
}
